{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from GoogletNet import GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 불러오기 및 전처리\n",
    "def load_and_preprocess_images(img_paths, target_size=(224,224)):\n",
    "    img_array_list = []\n",
    "    for img_path in img_paths:\n",
    "        img = np.array(Image.open(tf.io.gfile.GFile(img_path,'rb')).convert('RGB').resize(target_size, Image.BILINEAR), dtype=np.float32)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img_array_list.append(img)\n",
    "    return np.vstack(img_array_list)\n",
    "\n",
    "def create_cav_training_set(concepts, bottleneck, acts):\n",
    "    x = []\n",
    "    labels = []\n",
    "    labels2text = {}\n",
    "    min_data_points = np.min([acts[concept][bottleneck].shape[0] for concept in acts.keys()])\n",
    "\n",
    "    for I, concept in enumerate(concepts):\n",
    "        x.extend(acts[concept][bottleneck][:min_data_points].reshape(min_data_points, -1))\n",
    "        labels.extend([I] * min_data_points)\n",
    "        labels2text[I] = concept\n",
    "    \n",
    "    x = np.array(x)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return x, labels, labels2text\n",
    "\n",
    "def train_lm(lm, x, y, labels2text):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x, y, test_size=0.33, stratify=y)\n",
    "    \n",
    "    lm.fit(x_train, y_train)\n",
    "    y_pred = lm.predict(x_test)\n",
    "    \n",
    "    num_classes = max(y) + 1\n",
    "    acc = {}\n",
    "    num_correct = 0\n",
    "    for class_id in range(num_classes):\n",
    "      # get indices of all test data that has this class.\n",
    "      idx = (y_test == class_id)\n",
    "      acc[labels2text[class_id]] = metrics.accuracy_score(\n",
    "          y_pred[idx], y_test[idx])\n",
    "      # overall correctness is weighted by the number of examples in this class.\n",
    "      num_correct += (sum(idx) * acc[labels2text[class_id]])\n",
    "    acc['overall'] = float(num_correct) / float(len(y_test))\n",
    "    tf.compat.v1.logging.info('acc per class %s' % (str(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogLeNet()\n",
    "layer_names = ['mixed4c', 'mixed4d', 'mixed4e']\n",
    "concept_names = ['striped']\n",
    "random_concept_names = ['random1', 'random2', 'random3']\n",
    "concept_pairs = []\n",
    "\n",
    "for c in concept_names:\n",
    "    for rc in random_concept_names:\n",
    "        concept_pairs.append([c, rc])\n",
    "\n",
    "layer_outputs = [model.get_layer(name).output for name in layer_names]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_imgs = {}\n",
    "concepts = {}\n",
    "randoms = {}\n",
    "\n",
    "concept_path = glob.glob('test_data/striped/*')\n",
    "random_paths = [\n",
    "    glob.glob('test_data/random1/*'),\n",
    "    glob.glob('test_data/random2/*'),\n",
    "    glob.glob('test_data/random3/*')\n",
    "]\n",
    "\n",
    "concept_imgs = load_and_preprocess_images(concept_path)\n",
    "random_imgs = [load_and_preprocess_images(paths) for paths in random_paths]\n",
    "\n",
    "concepts['striped'] = concept_imgs\n",
    "input_imgs['concepts'] = concepts\n",
    "\n",
    "for i, random_img in enumerate(random_imgs):\n",
    "   randoms[f'random{i+1}'] = random_img\n",
    "\n",
    "input_imgs['randoms'] = randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 319ms/step\n",
      "2/2 [==============================] - 0s 86ms/step\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "2/2 [==============================] - 0s 79ms/step\n"
     ]
    }
   ],
   "source": [
    "for k in input_imgs.keys():\n",
    "    for k2 in input_imgs[k].keys():\n",
    "        activations = activation_model.predict(input_imgs[k][k2])\n",
    "        for i, act in enumerate(activations):\n",
    "            np.save(f'./acts/{k2}_{layer_names[i]}', act, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept: random2, Layer: mixed4c, Data shape: (42, 14, 14, 512)\n",
      "Concept: random2, Layer: mixed4d, Data shape: (42, 14, 14, 528)\n",
      "Concept: random2, Layer: mixed4e, Data shape: (42, 14, 14, 832)\n",
      "Concept: striped, Layer: mixed4c, Data shape: (50, 14, 14, 512)\n",
      "Concept: striped, Layer: mixed4e, Data shape: (50, 14, 14, 832)\n",
      "Concept: striped, Layer: mixed4d, Data shape: (50, 14, 14, 528)\n",
      "Concept: random1, Layer: mixed4e, Data shape: (44, 14, 14, 832)\n",
      "Concept: random1, Layer: mixed4d, Data shape: (44, 14, 14, 528)\n",
      "Concept: random1, Layer: mixed4c, Data shape: (44, 14, 14, 512)\n",
      "Concept: random3, Layer: mixed4e, Data shape: (40, 14, 14, 832)\n",
      "Concept: random3, Layer: mixed4d, Data shape: (40, 14, 14, 528)\n",
      "Concept: random3, Layer: mixed4c, Data shape: (40, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "# 딕셔너리 초기화\n",
    "acts = {}\n",
    "\n",
    "# 파일 불러와서 딕셔너리에 저장\n",
    "for file_path in glob.glob('./acts/*'):\n",
    "    # 파일 이름에서 concept와 layer 추출\n",
    "    file_name = os.path.basename(file_path)\n",
    "    parts = file_name.split('_')\n",
    "    concept = parts[0]\n",
    "    layer = parts[1].replace('.npy', '')\n",
    "    \n",
    "    # 데이터 불러오기\n",
    "    data = np.load(file_path)\n",
    "    \n",
    "    # 딕셔너리에 저장\n",
    "    if concept not in acts:\n",
    "        acts[concept] = {}\n",
    "    acts[concept][layer] = data\n",
    "\n",
    "# 결과 확인\n",
    "for concept, layers in acts.items():\n",
    "    for layer, data in layers.items():\n",
    "        print(f\"Concept: {concept}, Layer: {layer}, Data shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, labels, labels2text = create_cav_training_set(concept_pairs[1], 'mixed4c', acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.SGDClassifier(alpha=0.1, max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:acc per class {'striped': 0.8461538461538461, 'random2': 0.7142857142857143, 'overall': 0.7777777777777778}\n"
     ]
    }
   ],
   "source": [
    "acc = train_lm(lm, x, labels, labels2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cavs = [-1*lm.coef_[0], lm.coef_[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 남은거\n",
    "타겟 클래스와 개념의 cav과 계산 후 tcav 스코어 계산"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cavsi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
