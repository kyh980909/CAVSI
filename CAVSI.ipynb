{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "import SISE\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess image\n",
    "def preprocess_image(image_path, target_size=(299, 299)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    return img[0]\n",
    "\n",
    "# Function to generate semantic input samples\n",
    "def semantic_input_sampling(image, sample_size=100):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    samples = np.array([datagen.random_transform(image) for _ in range(sample_size)])\n",
    "    return samples\n",
    "\n",
    "# Explain instance using SISE\n",
    "def explain_instance_sise(image, model, sample_size=100):\n",
    "    samples = semantic_input_sampling(image, sample_size)\n",
    "    predictions = model.predict(samples)\n",
    "\n",
    "    # Flatten the samples for the regression model\n",
    "    feature_matrix = samples.reshape(samples.shape[0], -1)\n",
    "\n",
    "    weights = np.exp(-np.sum((samples - image) ** 2, axis=(1, 2, 3)) / 0.1)\n",
    "    surrogate_model = Ridge(alpha=1, fit_intercept=True)\n",
    "    surrogate_model.fit(feature_matrix, predictions, sample_weight=weights)\n",
    "\n",
    "    return surrogate_model.coef_\n",
    "\n",
    "# Visualize explanation\n",
    "def visualize_explanation(image, explanation, sample_size=100):\n",
    "    samples = semantic_input_sampling(image, sample_size)\n",
    "    top_features = np.argsort(np.abs(explanation))[-5:]\n",
    "    for i, sample in enumerate(samples):\n",
    "        if i in top_features:\n",
    "            plt.imshow(sample)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO UPDATE YOUR_PATH (where images, models are)!\n"
     ]
    }
   ],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "\n",
    "# This is the name of your model wrapper (InceptionV3 and GoogleNet are provided in model.py)\n",
    "model_to_run = 'GoogleNet'  \n",
    "user = 'yhkim'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"./tmp/\" + user + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir+ '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
    "source_dir = './tcav/tcav_examples/image_models/imagenet/test_data'\n",
    "bottlenecks = [ 'mixed4c', 'mixed4d', 'mixed4e']  # @param \n",
    "      \n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]\n",
    "\n",
    "target = 'zebra'\n",
    "concepts = [\"dotted\",\"striped\",\"zigzagged\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 15:21:02.690747: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-14 15:21:02.690937: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102967424/102967424 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Model load\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=True)\n",
    "# Preprocess the image\n",
    "image_path = \"./test_data/zebra/1_zebra1.jpg\"  # 로컬에 저장된 이미지 파일 경로\n",
    "image = preprocess_image(image_path)\n",
    "\n",
    "# Explain the image using SISE\n",
    "# explanation = explain_instance_sise(image, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sise = SISE(model, '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
